Computação Paralela Código: EIC0089     Sigla: CPAR Áreas Científicas Classificação Área Científica OFICIAL Programação Ocorrência: 2015/2016 - 2S Ativa? Sim Unidade Responsável: Departamento de Engenharia Informática Ciclos de Estudo/Cursos Sigla Nº de Estudantes Plano de Estudos Anos Curriculares Créditos UCN Créditos ECTS Horas de Contacto Horas Totais MIEIC 0 Plano de estudos a partir de 2009/10 4 - 6 42 162 Docência - Horas Teórico-Práticas: 3,00 Tipo Docente Turmas Horas Teórico-Práticas Totais 1 3,00 Jorge Manuel Gomes Barbosa 3,00 Língua de trabalhoPortuguês - Suitable for English-speaking students Objetivos ENQUADRAMENTO A programação paralela e distribuída está a tornar-se o paradigma comum de programação dada a evolução do hardware para arquiteturas multicore e elementos massivamente paralelos como as GPUs. O computador pessoal atual é composto por vários processadores que coletivamente disponibilizam maior capacidade de processamento, do que os anteriores single-core, mas que individualmente têm menor capacidade. Os programadores terão de dominar a programação multi-processador para que possam utilizar com eficiência as máquinas do presente e do futuro. OBJECTIVOS Aquisição de conhecimentos conducentes à utilização simultânea de várias unidades de processamento num sistema de computação. Construção de bases sólidas sobre arquiteturas paralelas, paralelização de algoritmos, modelos de programação, sincronização de processos e medidas de desempenho, através do desenvolvimento de programas. Componente ciêntifica:50% Componente técnica:50%   Resultados de aprendizagem e competências Os estudantes no final deverão ser capazes de: a) Analisar um problema e identificar o modelo de paralelização mais adequado (Conhecimento e compreensão) b) Escrever programas segundo o modelo de passagem de mensagens e memória partilhada (Análise e Prática) C) Elaborar soluções paralelas para novos problemas (Especificação) D) Utilização de modelos computacionais para estimar o tempo de computação das aplicações (Investigação) E) Conhecimentos de concorrência de processos e implementação de boas práticas para efetuar partilha de recursos (competências transferíveis). Modo de trabalhoPresencial Pré-requisitos (conhecimentos prévios) e co-requisitos (conhecimentos simultâneos) Os estudantes devem ter obtido aprovação às unidades curriculares de programação do 1º e 2º ano do curso. Programa INTRODUÇÃO: - Introdução à Computação Paralela. Medidas de desempenho: MIPS e FLOPS. Caracterização de desempenho: ?peak?, máximo e sustentável. Máquinas paralelas: processadores superescalares e vetoriais, organização de memória e redes de interligação. Efeito da gestão da memória cache no desempenho do processador ? Localização dos Dados. FUNDAMENTOS DA PROGRAMAÇÃO PARALELA: - Limitações da computação paralela (Amdahl Law). Tipos de paralelismos: paralelismo funcional, paralelismo de dados, streaming. Etapas na paralelização de um algoritmo: divisão em operações paralelas, padrões de comunicação, sincronização, granularidade e escalonamento (distribuição do trabalho pelos processadores). MODELOS DE PROGRAMAÇÃO PARALELA: Memória Partilhada e Memória Distribuída. Problemas de concorrência, secções criticas, ?False sharing?, operações de redução. PROGRAMAÇÃO DE MULTI-COMPUTADORES E MULTI-PROCESSADORES: - Utilização de MPI e OpenMP. - Outros frameworks e ferramentas. - Programação de GPUs para o paradigma de paralelismo de dados (CUDA). CARACTERIZAÇÃO DA COMPUTAÇÃO PARALELA: - Modelos de execução, Modelos de Computação, Medidas de Desempenho e Eficiência, Expansibilidade (Função de Isoeficiência). INTRODUÇÃO À COMPUTAÇÃO DISTRIBUÍDA EM AMBIENTE INTERNET: P2P, GRID, CLOUD COMPUTING. Aplicações e características. Bibliografia ObrigatóriaQuinn, Michael J.; Parallel programming in C with MPI and openMP. ISBN: 007-123265-6 Calvin Lin, Lawrence Snyder; Principles of parallel programming, Pearson - Addison Wesley, 2009. ISBN: 0-321-48790-7 David B. Kirk, Wen-mei W. Hwu; Programming massively parallel processors, Morgan Kaufman, 2010. ISBN: 978-0-12-381472-2 Bibliografia ComplementarFoster, Ian T.; Designing and building parallel programs. ISBN: 0-201-57594-9 Métodos de ensino e atividades de aprendizagem Exposição do material teórico com apresentação e discussão de exemplos. Desenvolvimento de alguns programas e exercícios práticos. Projecto e desenvolvimento de trabalhos de maior dimensão. SoftwareMicrosoft Visual Studio C++ MPI g++ Palavras ChaveCiências Tecnológicas > Tecnologia > Tecnologia de computadores > Tecnologia de software Tipo de avaliaçãoAvaliação distribuída com exame final Componentes de Avaliação Designação Peso (%) Exame 50,00 Participação presencial 0,00 Trabalho laboratorial 50,00 Total: 100,00 Componentes de Ocupação Designação Tempo (Horas) Estudo autónomo 60,00 Frequência das aulas 42,00 Trabalho laboratorial 60,00 Total: 162,00 Obtenção de frequência Não exceder o número de faltas (25%) e realizar e apresentar os trabalhos práticos. Fórmula de cálculo da classificação final Nota Final = 0.5*AvD + 0.5*Ex AvD ? Avaliação Distribuída Ex ? Nota do exame A Avaliação Distribuída é obtida por 2 trabalhos práticos, com peso idêntico cada um.   Avaliação especial (TE, DA, ...) A avaliação distribuída é baseada na realização de trabalhos práticos de programação ao longo do semestre, sendo opcional para regimes de ingresso especiais. Melhoria de classificação A melhoria da classificação obtida na componente distribuída pode ser realizada na próxima ocorrência da unidade curricular. A componente de Exame pode ser melhorada nas épocas previstas na FEUP. Observações Conhecimento de Linguagem C/C++
